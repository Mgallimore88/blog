{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Simple RAG Example\n",
    "Retreival Augmented Generation\n",
    "\n",
    "\n",
    "https://parlance-labs.com/education/rag/ben.html\n",
    "\n",
    "![rag-tree.webp](rag-tree.webp)\n",
    "\n",
    "\n",
    "- RAG is Retreival Augmented Generation. \n",
    "- It just means 'provide relevant context'\n",
    "- It works by \n",
    "1. creating an embedding from a prompt\n",
    "2. creating embeddings from sections of a document\n",
    "3.  finding the cosine similarity between the prompt and each section of the document.\n",
    "\n",
    "-Once the paragraph with the hightest cosine similarity to the prompt is found, the top 3 sentences are fed into a generative model to generate an answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U sentence-transformers\n",
    "# $pip install wikipedia-api\n",
    "# %pip install claudette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeg/miniforge3/envs/ai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from wikipediaapi import Wikipedia\n",
    "from claudette import Chat, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got the model list from here\n",
    "https://www.sbert.net/docs/sentence_transformer/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "model = SentenceTransformer('Alibaba-NLP/gte-base-en-v1.5', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch some text content and embed it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = Wikipedia('RAGBot/0.0', 'en')\n",
    "doc = wiki.page('Albert Einstein').text\n",
    "paragraphs = doc.split('\\n\\n')\n",
    "# ... make embedding\n",
    "docs_embed = model.encode(paragraphs, normalize_embeddings=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make an embedding of the prompt (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What gave Einstein the chance to meet his fellow neuroanatomist Ramon?\"\n",
    "query_embed = model.encode(query, normalize_embeddings=True)\n",
    "query_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5728152 , 0.47459427, 0.44192564, 0.47382304, 0.5413194 ,\n",
       "       0.43490496, 0.4756278 , 0.5182402 , 0.48718232, 0.41080484,\n",
       "       0.37724665, 0.57194126, 0.50365496, 0.46164155, 0.57233626,\n",
       "       0.5127679 , 0.52641445, 0.5398744 , 0.6040658 , 0.4396679 ,\n",
       "       0.47936997, 0.5163653 , 0.5112858 , 0.5028564 , 0.48975816,\n",
       "       0.40509236, 0.55507207, 0.5173719 , 0.47807235, 0.40626654,\n",
       "       0.3443527 , 0.39776003, 0.49057645, 0.5369898 , 0.33842805,\n",
       "       0.39533782, 0.31863862, 0.4034021 , 0.43526107, 0.42657036,\n",
       "       0.41576654, 0.44364488, 0.3890611 , 0.40116668, 0.50536174,\n",
       "       0.44676283, 0.3784415 , 0.44369176, 0.43291909, 0.42396727,\n",
       "       0.46925837, 0.37816215, 0.44824862, 0.48065543, 0.42301148,\n",
       "       0.37530896, 0.46815017, 0.4325635 , 0.3740057 , 0.53968686,\n",
       "       0.40272278, 0.37232846, 0.40951195, 0.42262912, 0.47417068,\n",
       "       0.46981564, 0.39782795, 0.31879896, 0.33717418], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "similarities = np.dot(docs_embed, query_embed)\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_idx = np.argsort(similarities)[::-1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18,  0, 14])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_documents = [paragraphs[idx] for idx in top_3_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = models[2]\n",
    "chat = Chat(llm, sp=f\"Here is some information from Wikipedia, it will help you to answer a question. Wikipedia information: {str(most_similar_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to the information provided, Einstein's 1923 visit to Spain gave him the chance to meet the fellow Nobel laureate, the neuroanatomist Santiago Ramón y Cajal. The passage states:\n",
       "\n",
       "\"(His Spanish trip also gave him a chance to meet a fellow Nobel laureate, the neuroanatomist Santiago Ramón y Cajal.)\"\n",
       "\n",
       "So Einstein's 1923 trip to Spain provided him the opportunity to meet and interact with the Nobel laureate neuroanatomist Santiago Ramón y Cajal.\n",
       "\n",
       "<details>\n",
       "\n",
       "- id: `msg_01Wu1ME2c2Chmg5x9Ej2Tohm`\n",
       "- content: `[{'text': 'According to the information provided, Einstein\\'s 1923 visit to Spain gave him the chance to meet the fellow Nobel laureate, the neuroanatomist Santiago Ramón y Cajal. The passage states:\\n\\n\"(His Spanish trip also gave him a chance to meet a fellow Nobel laureate, the neuroanatomist Santiago Ramón y Cajal.)\"\\n\\nSo Einstein\\'s 1923 trip to Spain provided him the opportunity to meet and interact with the Nobel laureate neuroanatomist Santiago Ramón y Cajal.', 'type': 'text'}]`\n",
       "- model: `claude-3-haiku-20240307`\n",
       "- role: `assistant`\n",
       "- stop_reason: `end_turn`\n",
       "- stop_sequence: `None`\n",
       "- type: `message`\n",
       "- usage: `{'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 1957, 'output_tokens': 119}`\n",
       "\n",
       "</details>"
      ],
      "text/plain": [
       "Message(id='msg_01Wu1ME2c2Chmg5x9Ej2Tohm', content=[TextBlock(text='According to the information provided, Einstein\\'s 1923 visit to Spain gave him the chance to meet the fellow Nobel laureate, the neuroanatomist Santiago Ramón y Cajal. The passage states:\\n\\n\"(His Spanish trip also gave him a chance to meet a fellow Nobel laureate, the neuroanatomist Santiago Ramón y Cajal.)\"\\n\\nSo Einstein\\'s 1923 trip to Spain provided him the opportunity to meet and interact with the Nobel laureate neuroanatomist Santiago Ramón y Cajal.', type='text')], model='claude-3-haiku-20240307', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 1957; Out: 119; Cache create: 0; Cache read: 0; Total: 2076)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements\n",
    "__Cross Encoder__\n",
    "- This method use a Bi-encoder model. It is very efficient, since the embeddings for the document can be computed in parallel, and stored in a database, so that in the end all that you need to look up is the similarity between the prompt embedding and the embeddings stored in a database. \n",
    "\n",
    "The documents and query representations are computed entirely separately in the bi-encoder, so they aren't aware of each other. \n",
    "Improvements can be made by using a Cross-encoder model. These essentially are a binary classifier, where p(positive class) is taken as the similarity score. These are slower than bi-encoders, but are more accurate.\n",
    "\n",
    "\n",
    "<img src=\"cross-encoder.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reranking__\n",
    "Cross encoders are computationally expensive to run, so using a cross-encoder on the entire set of documents, for every prompt, would take a long time. \n",
    "One solution is to return a shortlist of documents using a computationally efficient approach, such as a bi-encoder, and then re-rank these by using a cross-encoder. There's a library for this - github.com/answerdotai/rerankers \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Keyword Search__\n",
    "always have keyword search and full text search in the pipeline. \n",
    "\n",
    "__tf-idf__ term frequency-inverse document frequency weighs down common words and weighs up rare words. \n",
    "\n",
    "__BM25__ is a way to implement tf-idf. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
