[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mike’s Machine Learning Blog",
    "section": "",
    "text": "What is an embedding layer and how does it work?\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nBuilding a boat recognizer using the fast.ai library\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nExploring the capability of neural networks to solve simple linear and nonlinear algebraic equations.\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nExploring probability distributions\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#choose-a-set-of-categories-for-the-classification-model",
    "href": "posts/BCE-model/BCEmodel.html#choose-a-set-of-categories-for-the-classification-model",
    "title": "MG ML",
    "section": "Choose a set of categories for the classification model",
    "text": "Choose a set of categories for the classification model\n\nboat_types = 'canoe', 'kayak', 'sailboat'\n\n\npath = Path('boats')\n\nDownload images from chosen categories.\nThis cell may take a few minutes to run\n\nif not path.exists():\n    path.mkdir()\n    for boat in boat_types:\n        dest = (path/boat)\n        dest.mkdir(exist_ok=True)\n        results = search_images(boat)\n        download_images(dest, urls=results)\n\n\n!ls {path}\npath\n\ncanoe  kayak  sailboat\n\n\nPath('boats')\n\n\n\nfilenames = get_image_files(path)\nfilenames\n\n(#554) [Path('boats/sailboat/3b873c96-0d1f-4404-9aae-af25d3805177.jpg'),Path('boats/sailboat/6336c57d-8ad9-4318-836c-fba58b5357be.jpg'),Path('boats/sailboat/d2a981d0-0d3e-4b0e-a077-a5cbda1a41b0.JPG'),Path('boats/sailboat/da7dc60e-7c83-4807-9fc1-a0f5061a5080.jpg'),Path('boats/sailboat/168643af-803b-4783-8c6b-a785157c481e.jpeg'),Path('boats/sailboat/f4055206-199c-42a8-bf74-8ed6c4dc7e08.jpg'),Path('boats/sailboat/d5883260-5325-41cb-a645-016051c37819.jpg'),Path('boats/sailboat/4b44e5d8-75e1-413b-a9b9-bd3f19b63df4.jpg'),Path('boats/sailboat/86d8f1b9-b75b-467f-8476-2d91805a150b.jpg'),Path('boats/sailboat/e07b4c1d-a717-4c10-9059-005016798081.jpeg')...]"
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#some-of-the-terminology-in-pytorch-fastai-can-be-confusing.-they-can-have-similar-names-which-mean-very-specific-things.-here-are-some-definintions",
    "href": "posts/BCE-model/BCEmodel.html#some-of-the-terminology-in-pytorch-fastai-can-be-confusing.-they-can-have-similar-names-which-mean-very-specific-things.-here-are-some-definintions",
    "title": "MG ML",
    "section": "Some of the terminology in PyTorch fastai can be confusing. They can have similar names which mean very specific things. Here are some definintions",
    "text": "Some of the terminology in PyTorch fastai can be confusing. They can have similar names which mean very specific things. Here are some definintions\nDataset: an iterable over tuples containing images with their corresponding category.  Datasets: a fastai class which joins together a training dataset and a validation dataset into one object. DataLoader: a PyTorch iterable returning a batch of datasets. DataLoaders: a fastai iterable which splits dataloaders into training and validation datasets.  batch: The sample of the dataset loaded in parallel and passed to the model during one training loop."
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#use-the-fastai-datablock-to-create-a-way-to-load-datasets-and-dataloaders",
    "href": "posts/BCE-model/BCEmodel.html#use-the-fastai-datablock-to-create-a-way-to-load-datasets-and-dataloaders",
    "title": "MG ML",
    "section": "Use the fastai DataBlock to create a way to load datasets and dataloaders",
    "text": "Use the fastai DataBlock to create a way to load datasets and dataloaders\n\nboats = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128)\n)\n\n\ndataloaders = boats.dataloaders(path)\n\nThe dataloaders object provides a way of loading batches of data from a location. It contains specific details on how the data should be transformed, how big a validation set to make, and a bunch of helper functions such as show.batch() which allow quick visualization and troubleshooting."
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#training-and-validation-sets",
    "href": "posts/BCE-model/BCEmodel.html#training-and-validation-sets",
    "title": "MG ML",
    "section": "Training and validation sets",
    "text": "Training and validation sets\nOur data is split into training and validation sets. 20% of the data is in the validation set, and 80% is in the training set.\nHere we can see a sample of one batch from the training set. The input feature is an image of a boat, and the target label is the class of the boat. There are three classes: canoe, sailboat and kayak. We can see using the show_batch function that the images and labels are all loaded and re-sized correctly.\n\ndataloaders.train.show_batch()"
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#pre-trained-models.",
    "href": "posts/BCE-model/BCEmodel.html#pre-trained-models.",
    "title": "MG ML",
    "section": "Pre-trained models.",
    "text": "Pre-trained models.\nHere we take a pre-trained image recognition model and fine tune it to learn the classes in our dataset. This resnet18 model was originally trained on the ImageNet dataset to recognize over 20,000 classes, with hundreds of examples in each class. We can take advantage of the large amount of work which went into training this model.\nUnder the hood fastai replaces the output layers of the pre-trained model with randomly initialized layers with the same number of output nodes as the number of classes we’re trying to predict (three: ‘canoe’, ‘kakak’, ‘sailboat’). When we re-train the model, most of the work goes into training these final layers of the network, until the model learns to represent the categories we’re looking for. This works even when the category we’re looking for wasn’t seen by the pre-trained model’s original dataset.\nThe earlier layers of a neural network tend to learn things like gradients, edges, colour, and the semantic meaning increases in deeper layers until the final layer represents the concept level output: canoe, kayak, sailboat. These earlier layers are useful for picking out features in a broad set of images - not just the ones the model was trained on."
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#metrics",
    "href": "posts/BCE-model/BCEmodel.html#metrics",
    "title": "MG ML",
    "section": "Metrics",
    "text": "Metrics\nMetrics are a human readable representation of the performance of our model. Error rate is a pretty simple and easy to understand metric: what portion of the examples from the validation set did we mis-classify."
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#loss",
    "href": "posts/BCE-model/BCEmodel.html#loss",
    "title": "MG ML",
    "section": "Loss",
    "text": "Loss\nLoss can be thought of as a sort of punishment function. The training process seeks to minimize loss, and the gradient of the loss function is used to calculate a better set of parameters during model training. The loss function can be thought of as a kind of error measure, but it is designed to be read by a machine, not a human, and to have smooth gradients. Lower loss usually means a better model. When plotting loss per epoch, decreasing loss curves are a good sign which mean the model is improving. If the loss curves are noisy or increasing, it is an indicator that we might have picked too high a learning rate, or that the model is beginnign to over-fit.\n\nlearn = vision_learner(dataloaders, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\nlearn.recorder.plot_loss()\n\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.571849\n      0.666472\n      0.163636\n      00:14\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.534734\n      0.270972\n      0.118182\n      00:15\n    \n    \n      1\n      0.436475\n      0.234348\n      0.081818\n      00:15\n    \n    \n      2\n      0.353536\n      0.214399\n      0.063636\n      00:15\n    \n    \n      3\n      0.313201\n      0.206994\n      0.063636\n      00:14"
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#great-again-we-got-a-sensible-preciction-of-88-probability-of-a-canoe.",
    "href": "posts/BCE-model/BCEmodel.html#great-again-we-got-a-sensible-preciction-of-88-probability-of-a-canoe.",
    "title": "MG ML",
    "section": "Great, again we got a sensible preciction of 88% probability of a canoe.",
    "text": "Great, again we got a sensible preciction of 88% probability of a canoe.\n\nprediction, index, probs = learn.predict('images/leaves.jpg')\nprint(f\"The model predicted {prediction} with a confidence of {probs[index]}\")\nprint(probs)\nImage.open('images/leaves.jpg')\n\n\n\n\n\n\n\n\nThe model predicted canoe with a confidence of 0.5352954268455505\nTensorBase([0.5353, 0.1248, 0.3399])"
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html#first-we-need-to-create-a-function-to-get-the-label",
    "href": "posts/BCE-model/BCEmodel.html#first-we-need-to-create-a-function-to-get-the-label",
    "title": "MG ML",
    "section": "First we need to create a function to get the label",
    "text": "First we need to create a function to get the label\nWe already have this, in the form of parent_label(), which returns a string version of the parent folder containing the image. However, we’re also going to tell fastai that the labels are multi-category labels, even though they’re not. The multi-category block expects a list of strings as input - so if we just pass in a string then that will get split into a list of characters - not what we want.\nI’m doing this so that the labels are converted to one hot encoded vectors, which will allow us to use binary cross-entropy loss.\nSpecifying the target type as ‘MultiCategoryBlock’ in the fastai DataBlock will create a model which can handle multiple classes in a single image. Rather than strongly picking one class out of many, we’ll be choosing potentially many classes out of many. This has the beneficial side effect that we can threshold the output activations and create a ‘no class recognized’ output - an ability we don’t have when using cross-entropy loss across all the activations.\n\ndef get_y(r): return parent_label(r).split(' ')\n\n\ndef accuracy_multi(inp, targ, thresh=0.5, sigmoid=True):\n    \"Compute accuracy when `inp` and `targ` are the same size.\"\n    if sigmoid: inp = inp.sigmoid()\n    return ((inp>thresh)==targ.bool()).float().mean()\n\n\nboat_dls = DataBlock(\n    blocks=(ImageBlock, MultiCategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=get_y,\n    item_tfms=Resize(128),\n    batch_tfms=aug_transforms()\n).dataloaders(path)\n\n\nlr = learn.lr_find()\n\n\n\n\n\n\n\n\n\n\n\n\nlearn = vision_learner(boat_dls, resnet18, pretrained=True, metrics=accuracy_multi)\n%time learn.fine_tune(6, base_lr=lr[0])\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      1.020967\n      0.877902\n      0.563636\n      00:13\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      accuracy_multi\n      time\n    \n  \n  \n    \n      0\n      0.947158\n      0.818463\n      0.545455\n      00:14\n    \n    \n      1\n      0.937178\n      0.750471\n      0.572727\n      00:13\n    \n    \n      2\n      0.897594\n      0.689925\n      0.627273\n      00:14\n    \n    \n      3\n      0.863008\n      0.640909\n      0.654545\n      00:14\n    \n    \n      4\n      0.827849\n      0.622816\n      0.663636\n      00:13\n    \n    \n      5\n      0.808169\n      0.619115\n      0.660606\n      00:14"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in my ML blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/linear-nonlinear-neuralnet/linear-nonlinear-neuralnet.html",
    "href": "posts/linear-nonlinear-neuralnet/linear-nonlinear-neuralnet.html",
    "title": "MG ML",
    "section": "",
    "text": "Topics covered: - PyTorch - Feature Crosses - Linear and nonlinear models - universal approximation theorem - interpreting loss curves\nIn this example, I asked chat GPT to generate a PyTorch training loop for a linear model, from a synthetic dataset. The code produced was great. It gave me ideas and some framework code from which to develop my own understanding. Modifying and developing the code was a quick way to explore some new functions and explore some ideas in an interactive way.\nI wanted to get an intuitive understanding of the universal approximation theorem, in order to be able to better decide when to choose a neural network, and when to choose another type of model."
  },
  {
    "objectID": "posts/linear-nonlinear-neuralnet/linear-nonlinear-neuralnet.html#define-a-nonlinear-model",
    "href": "posts/linear-nonlinear-neuralnet/linear-nonlinear-neuralnet.html#define-a-nonlinear-model",
    "title": "MG ML",
    "section": "Define a nonlinear model",
    "text": "Define a nonlinear model\nThis model will contain two linear layers connected by a ReLU activation function, enabling it to represent nonlinear functions.\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(10,10),\n    torch.nn.ReLU(),\n    torch.nn.Linear(10,1)\n)\n\n\n# Define the optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n\noptimizer\n\nSGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    lr: 0.01\n    maximize: False\n    momentum: 0\n    nesterov: False\n    weight_decay: 0\n)\n\n\n\n# Define the data loader\nloader = DataLoader(train_dataset, batch_size=500, shuffle=True)\n\n\ntrain(100, loader, model, val_x, val_y)\n\n2.518, 1.761\n\n\n\n\n\nThe model converges towards a stable value, but it takes a long time and never reaches zero. This can be explained by the model not describing the mapping function perfectly - it is almost but not quite describing the equation\n\\(y=2X_0X_1 + 2X_0 -3X_1 - 3\\)\nSince we increased the number of layers in the model, interpreting what is going on by looking at the parameters has gone from being trivial to being very difficult. We are looking for coefficients which represent a straight multiplication of \\(2 * X_0\\), \\(-3 * X_1\\) and some way of representing \\(2*X_0*X_1\\)\n\nlist(model.parameters())\n\n[Parameter containing:\n tensor([[-6.0341e-01,  7.4068e-01,  1.1714e-01,  3.0487e-01,  1.1350e-01,\n           1.6252e-01, -3.8328e-01,  2.9286e-01, -1.7268e-01, -1.1349e-01],\n         [-9.7725e-01,  1.2587e+00, -9.1938e-02, -1.3213e-01,  2.7093e-02,\n          -1.1980e-01,  9.9834e-02, -2.4829e-01,  1.9772e-01, -8.2101e-03],\n         [-4.7922e-01,  5.4561e-01,  1.7990e-01, -1.3366e-01, -5.8698e-02,\n           2.0070e-01,  1.2817e-01,  2.6042e-02,  7.4049e-02,  1.5992e-02],\n         [-1.1129e-01, -3.4661e-01,  1.5593e-02, -3.3927e-02,  3.3553e-03,\n          -6.7739e-02,  1.9699e-01, -2.1908e-01, -1.9680e-01,  1.2308e-01],\n         [ 6.4029e-04,  1.1276e-01, -2.5297e-01,  2.1831e-01, -1.1878e-01,\n          -1.4201e-01,  3.0204e-01, -1.6409e-01, -1.6396e-01,  1.7286e-01],\n         [-3.0487e-01,  2.8155e-01,  9.8999e-02, -2.4160e-01, -2.4192e-01,\n          -1.1160e-01, -2.1963e-02,  7.1207e-03,  2.8266e-01,  1.1177e-01],\n         [-4.3329e-03,  2.6280e-01, -2.4909e-01, -1.4999e-01,  2.7082e-01,\n          -3.0941e-01, -4.8501e-02,  1.5773e-01, -2.4637e-01,  2.7581e-01],\n         [ 8.0356e-02, -5.0721e-01,  1.0275e-02, -1.4435e-01, -2.3078e-01,\n           1.5244e-01, -2.5871e-01,  2.0775e-01,  1.6999e-02,  1.4378e-01],\n         [-8.0510e-01,  9.3808e-01,  2.7476e-02,  4.1569e-02, -8.0434e-02,\n          -8.6201e-02, -5.4608e-02,  6.5882e-02, -3.5787e-01, -6.5858e-02],\n         [-1.0937e-01, -4.4521e-01,  8.5424e-02, -1.5546e-01, -6.3826e-02,\n           3.4240e-02, -2.7848e-01,  2.5718e-01, -1.5809e-01, -8.6447e-02]],\n        requires_grad=True),\n Parameter containing:\n tensor([ 0.0198,  0.4470,  0.2590,  0.2427,  0.2077,  0.0263, -0.1412,  0.2742,\n          0.1831,  0.1076], requires_grad=True),\n Parameter containing:\n tensor([[-0.9906, -1.6195, -0.7937,  0.3644, -0.0268, -0.4274, -0.0493,  0.2982,\n          -1.2422,  0.3623]], requires_grad=True),\n Parameter containing:\n tensor([-0.2686], requires_grad=True)]\n\n\nPerhaps we can work out the correct set of parameters for the model just by thinking about it…\nThe first node of the first layer needs to carry through the exact values of \\(X_0\\) and \\(X_1\\) so they can be used later.\nWe also need these \\(X_0\\) and \\(X_1\\) features to be multiplied by the weights 2 and -3 for the linear part of the problem.\nWe’d need an overall bias of -3, which is added to the output layer of the model.\nFinally need a point in the model where \\(X_0\\) and \\(X_1\\) are multiplied together. This never happens - unless we have a quadratic activation function. We’re providing nonlinearities using ReLUs (rectified linear units). A ReLU is like two linear functions (y=x and y=0) joined at a discontinuity at x=0.\n\nk = torch.linspace(-100, 100, 20000)\nrelu = torch.relu(k)\nplt.plot(k, relu)\nplt.title('Using a ReLU activation function after each node in a linear layer \\nis one way to add a nonlinearity to a neural network')\n\nplt.show()\n\n\n\n\n\ntrain(5000, loader, model, val_x, val_y)\n\n0.172, 0.177\n\n\n\n\n\nThis model is trained pretty well. Let’s make a plot of y vs model(x) and see what shape we get.\n\nplt.scatter(model(X).detach().numpy(), y, alpha=0.05)\n\n<matplotlib.collections.PathCollection at 0x1378a83a0>\n\n\n\n\n\nThere are outliers visible. After training for 5000 epochs, the model has found a way of approximating our nonlinear function using a combination of coefficients and nonlinear activation functions. It isn’t perfect though - since functions which build the model are all linear additions and multiplications by ReLU."
  },
  {
    "objectID": "posts/linear-nonlinear-neuralnet/linear-nonlinear-neuralnet.html#make-the-synthetic-dataset",
    "href": "posts/linear-nonlinear-neuralnet/linear-nonlinear-neuralnet.html#make-the-synthetic-dataset",
    "title": "MG ML",
    "section": "Make the synthetic dataset",
    "text": "Make the synthetic dataset"
  },
  {
    "objectID": "posts/linear-nonlinear-neuralnet/linear-nonlinear-neuralnet.html#define-a-nonlinear-model-1",
    "href": "posts/linear-nonlinear-neuralnet/linear-nonlinear-neuralnet.html#define-a-nonlinear-model-1",
    "title": "MG ML",
    "section": "Define a nonlinear model",
    "text": "Define a nonlinear model\nThis model will contain two linear layers connected by a ReLU activation function, enabling it to represent nonlinear functions.\n\nmodel = torch.nn.Sequential(\n    torch.nn.Linear(1,10),\n    torch.nn.ReLU(),\n    torch.nn.Linear(10,10),\n    torch.nn.ReLU(),\n    torch.nn.Linear(10,1),\n)\n\n\n# Define the optimizer\noptimizer = torch.optim.Adam(model.parameters())\n\n\n# Define the data loader\nloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n\n\ntrain(500, loader, model, val_x, val_y)\n\n0.000, 0.000\n\n\n\n\n\n\nplt.scatter(x,y)\nyhat = model(x).detach().numpy()\nplt.scatter(x, yhat)\n\n<matplotlib.collections.PathCollection at 0x297771ab0>\n\n\n\n\n\nI haven’t been able to get the model to train sufficiently for this problem. Here’s another blog post showing that it is possible, and that the resulting model doesn’t have any smooth segments on its curve:\nhttps://machinelearningmastery.com/neural-networks-are-function-approximators/"
  },
  {
    "objectID": "posts/probability-distributions/Probability.html",
    "href": "posts/probability-distributions/Probability.html",
    "title": "MG ML",
    "section": "",
    "text": "dice\n\n\nWhat happens when we add two sets of data with rectangular probability distributions?\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nn_samples = 100000\nhist_bins = 200\n\n\ndata_1 = np.random.rand(n_samples)\nplt.hist(data_1, bins=hist_bins)\nplt.show()\n\n\n\n\n\ndata_2 = np.random.rand(n_samples)\ndata_2 = data_1 + data_2\nplt.hist(data_2, bins=hist_bins)\nplt.show()"
  },
  {
    "objectID": "posts/probability-distributions/Probability.html#now-we-see-a-bell-curve.",
    "href": "posts/probability-distributions/Probability.html#now-we-see-a-bell-curve.",
    "title": "MG ML",
    "section": "Now we see a bell curve.",
    "text": "Now we see a bell curve.\nThe shape of this curve can be understood by looking at a table of the odds of each roll combination of three six-sided dice:\n\n\n\n“dice3d6”"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi! I’m a software engineer living in Squamish BC, Canada. I moved out here to pursue a life in the mountains.\nA graduate of Acoustics, I have experience in electronics, digital signal processing, mechanical engineering, and a good math background.\nI am proficient in Python. I studied Machine Learning through the FastAI course and textbooks. I’ve gained a solid practical understanding of how to build and train ML models including convolutional neural networks, random forests, segmentation models, and collaborative filtering models.\nCurrently I’m working on a project to identify animal species in audio recordings."
  },
  {
    "objectID": "posts/BCE-model/BCEmodel.html",
    "href": "posts/BCE-model/BCEmodel.html",
    "title": "MG ML",
    "section": "",
    "text": "leaves\n\n\nIn this notebook we build and train a convolutional neural network based classifier model in PyTorch recognize images of canoes, kayaks and sailboats. We use the fastai library to speed up the process and get us to a working model with less code.\nThis notebook was used for a presentation at ML Squamish to take first time coders from a no-code background to training their first image recognition model in an evening.\nWe explore some different loss functions and training approaches.\nTopics covered: - Training and validation sets - Image augmentations - Cross entropy loss - Binary Crossentropy Loss - Learning rate finder\nLet’s get started!"
  },
  {
    "objectID": "posts/embeddings/embeddings.html",
    "href": "posts/embeddings/embeddings.html",
    "title": "MG ML",
    "section": "",
    "text": "In this example I’ll make a collaborative filtering model (recommender system) which uses an entity embedding as part of a system for recommending books to users.\nEmbeddings are a neat way to take a large number of individual items (users, products, locations for example), and represent each item using an n-dimensional vector instead of using its unique id. At first this might sound like it would increase the size and complexity of the model - since each item now needs an additional vector representation - but in fact this process reduces the number of individual inputs the model needs to see to be able to make predictions.\nFor example, if we had an embedding for 1000 book titles, without an embedding layer the model would need to see each unique ID and learn the difference between them. An embedding vector for each of these book titles might be 2 dimensions deep, and might encode for each book’s sci-fi-ness and its length. This means we could feed this two dimensional embedding vector as input to the model rather than the 1000 individual titles. Since those inputs represent something real about the book, that might be enough information to make sensible predictions with. In a sense the embedding compresses information about each of the N inputs into an n dimensional vector.\nIn this blog post I’ll follow a similar process to the one outlined in the fast.ai course which used the movielens dataset. I’ll aim to explain some nuances about embedding layers, since I found this concept pretty confusing at first. Now that I’ve got my head around them I’m pretty amazed at how elegant, powerful and useful embeddings can be, and I’m excited to start trying out creative uses for embeddings.\nRead more on embeddings in this paper: Guo, Cheng et al. “Entity Embeddings of Categorical Variables”\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom fastai.collab import *\nfrom fastai.tabular.all import *\n\n\ndef display_all(df):\n    with pd.set_option('display.max_columns', 0, 'display.max_rows', 0):\n        print(df)\n\n\npath = Path('/kaggle/input/book-recommendation-dataset/')"
  },
  {
    "objectID": "posts/embeddings/embeddings.html#embeddings",
    "href": "posts/embeddings/embeddings.html#embeddings",
    "title": "MG ML",
    "section": "Embeddings",
    "text": "Embeddings\nSince there are hundreds of thousands of individual user IDs, and many more book titles, it will be useful to compress this data in some way - in a way which keeps the relevant information about each user and book, but doesn’t require the model to learn each individual user ID or book title. This is where Embeddings come in handy.\n\ndls = CollabDataLoaders.from_df(ratings, item_name='title', bs=16)"
  },
  {
    "objectID": "posts/embeddings/embeddings.html#take-a-sample",
    "href": "posts/embeddings/embeddings.html#take-a-sample",
    "title": "MG ML",
    "section": "Take a sample",
    "text": "Take a sample\nTo speed up development and testing We’ll work with a random sample of 300,000 users from the dataset.\n\nnumber_of_samples = 300000\ndf=ratings.sample(number_of_samples)\ndls = CollabDataLoaders.from_df(df, item_name='title', bs=64)"
  },
  {
    "objectID": "posts/embeddings/embeddings.html#sample-only-popular-books-and-users-with-lots-of-entries.",
    "href": "posts/embeddings/embeddings.html#sample-only-popular-books-and-users-with-lots-of-entries.",
    "title": "MG ML",
    "section": "Sample only popular books and users with lots of entries.",
    "text": "Sample only popular books and users with lots of entries.\nDeliberately selecting from the most read titles, and the most active readers could be a way of getting the information density up a little. This is definitely a design decision which should be scrutinized, since it biases the system towards more popular items, but it could be a good way to jumpstart training.\nPlus it doesn’t make a lot of sense to be training a collaborative filtering model on users who have read only one book: there wouldn’t be any second item to lookup and recommend for another user who has read the same book.\n\nbook_count = len(set(ratings.title))\npopular_books = ratings.title.value_counts()[:1000].keys()\n\nreader_count = len(set(ratings.user))\navid_readers = ratings.user.value_counts()[:1000].keys()\n\n\nlen(ratings)\n\n1031136\n\n\nOverwriting the variable dense_df with this new selection\n\ndense_df = ratings[ratings.title.isin(popular_books)]\ndense_df = (dense_df[dense_df.user.isin(avid_readers)])\nprint(len(dense_df))\n\n76402\n\n\nNow we’ve got the number of samples in the database down to 76402, and it only contains the top 1000 readers and the top 1000 books."
  },
  {
    "objectID": "posts/embeddings/embeddings.html#make-a-new-dataloaders-object-to-draw-training-and-validation-samples-from-this-new-dataframe.",
    "href": "posts/embeddings/embeddings.html#make-a-new-dataloaders-object-to-draw-training-and-validation-samples-from-this-new-dataframe.",
    "title": "MG ML",
    "section": "Make a new dataloaders object to draw training and validation samples from this new dataframe.",
    "text": "Make a new dataloaders object to draw training and validation samples from this new dataframe.\n\ndense_dls = CollabDataLoaders.from_df(dense_df, item_name='title', bs=64)\nn_users = len(dense_dls.classes['user'])\nn_titles = len(dense_dls.classes['title'])\n\n\nmodel = DotProduct(n_users, n_titles, n_factors=50)"
  },
  {
    "objectID": "posts/embeddings/embeddings.html#lets-see-how-the-model-trains-now",
    "href": "posts/embeddings/embeddings.html#lets-see-how-the-model-trains-now",
    "title": "MG ML",
    "section": "Let’s see how the model trains now",
    "text": "Let’s see how the model trains now\n\nlearn = Learner(dense_dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 1e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.169560\n      0.172441\n      00:06\n    \n    \n      1\n      0.119379\n      0.122923\n      00:06\n    \n    \n      2\n      0.103940\n      0.114699\n      00:06\n    \n    \n      3\n      0.098195\n      0.113169\n      00:06\n    \n    \n      4\n      0.099816\n      0.113051\n      00:06\n    \n  \n\n\n\n\nGreat - the training only takes 5s per epoch, and we’re still seeing convergence after 5 epochs. Let’s try to improve from here"
  },
  {
    "objectID": "posts/embeddings/embeddings.html#thinking-about-latent-factors-as-components-of-a-vector-in-an-n-dimensional-feature-space",
    "href": "posts/embeddings/embeddings.html#thinking-about-latent-factors-as-components-of-a-vector-in-an-n-dimensional-feature-space",
    "title": "MG ML",
    "section": "Thinking about latent factors as components of a vector in an n-dimensional feature space",
    "text": "Thinking about latent factors as components of a vector in an n-dimensional feature space\nHere are the factors for each of the users in the batch:\n\nmodel.user_factors(batch[:,0])\n\ntensor([[ 0.0206,  0.0324, -0.0256,  ..., -0.0972,  0.0861, -0.0837],\n        [ 0.0978,  0.1441,  0.0092,  ..., -0.0022, -0.0379,  0.0745],\n        [-0.0334,  0.0943,  0.0024,  ...,  0.0780, -0.0867, -0.0408],\n        ...,\n        [ 0.0150,  0.0170,  0.0297,  ...,  0.0246, -0.0477, -0.0407],\n        [-0.0341, -0.0660, -0.0711,  ...,  0.0390,  0.0392,  0.0218],\n        [ 0.0929,  0.0700,  0.0584,  ...,  0.0826, -0.0621,  0.0504]],\n       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n\n\nEach of these numbers represents a learned latent factor for that user. The latent factors can can be thought of as the contribution / component to a vector in n-dimensional space, where each number is a different axis’s contribution. The factors are all orthoganal to oneanother. They can represent things like taste, genre, age etc.\nFor example: if user A has 3 latent factors x, y, z, and these have values 1, 0.2, -0.9, then we can imagine a vector in 3d space which extends along the x dimension by 1, along y by 0.2, and extends negatively along the z dimension by 1.\nAnother user, or book title, might point in a very similar direction. This would mean that their factors overlap a lot and tend not to cancel out.\nEach of these dimensions could code for something like ‘enjoys horror books’, ‘enjoys shorter books’, younger.\nIf there was another user who’s factors were -1, 0.2, 1, we might say that they had the opposite taste for horror stories, that they have the same liking for shorter books, and that they are older.\nThe latent factors encode for real world meaning, but the factors themselves aren’t chosen by the engineer when setting up the neural network - rather they emerge from the relationships between books, users and ratings as the model trains."
  },
  {
    "objectID": "posts/embeddings/embeddings.html#finding-the-books-with-the-highest-bias",
    "href": "posts/embeddings/embeddings.html#finding-the-books-with-the-highest-bias",
    "title": "MG ML",
    "section": "Finding the books with the highest bias",
    "text": "Finding the books with the highest bias\nHere’s a list of books with a high bias: they end up having a higher rating across the board, despite the specific features which were learned to describe the books. Intuitively this means that they’re high quality - since they get consistently high ratings despite their genre and the users’ tastes.\n\nbooks_bias = learn.model.title_bias.weight.squeeze()\nidxs = books_bias.argsort(descending=True)[:20]\n[dense_dls.classes['title'][i] for i in idxs]\n\n['Harry Potter and the Order of the Phoenix (Book 5)',\n 'Harry Potter and the Prisoner of Azkaban (Book 3)',\n \"Harry Potter and the Sorcerer's Stone (Book 1)\",\n 'Harry Potter and the Chamber of Secrets (Book 2)',\n 'To Kill a Mockingbird',\n '84 Charing Cross Road',\n \"Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\",\n 'The Lovely Bones: A Novel',\n 'A Wrinkle in Time',\n 'Harry Potter and the Goblet of Fire (Book 4)',\n 'The Little Prince',\n 'The Secret Garden',\n 'The Da Vinci Code',\n 'Girl in Hyacinth Blue',\n 'Stupid White Men ...and Other Sorry Excuses for the State of the Nation!',\n 'Lord of the Flies',\n 'Dragonfly in Amber',\n \"Dude, Where's My Country?\",\n 'Fahrenheit 451',\n 'Carrie']"
  }
]